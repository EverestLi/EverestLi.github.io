<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="《深度学习推荐系统》学习笔记，系统的梳理经典模型、深度学习模型、Embedding技术、系统工程、工程实现和评估。">
<meta property="og:type" content="article">
<meta property="og:title" content="推荐系统技术综述">
<meta property="og:url" content="http://example.com/2022/02/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/index.html">
<meta property="og:site_name" content="Matrix">
<meta property="og:description" content="《深度学习推荐系统》学习笔记，系统的梳理经典模型、深度学习模型、Embedding技术、系统工程、工程实现和评估。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723152202.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716162049.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180149313.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180201157.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180216076.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308181906910.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309174159397.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309175621479.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309175833957.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309181114489.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309181137010.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310204002189.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310204819943.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205113107.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205324107.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205421359.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205512459.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103813814.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310221917734.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103823700.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310223257498.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103835285.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312095422634.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312101802053.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312104749343.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312105705554.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312112146955.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312195738770.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313110753122.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313111741551.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313112005607.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313112106849.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313131344283.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313131555230.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313133304540.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313140757732.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313141634399.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313144640704.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313145940140.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313145950401.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220621222418.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716162946.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716163428.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716163839.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716165503.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716165650.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716170027.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716172722.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220716174108.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718153130.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718155048.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718155248.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718155500.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718160407.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718161238.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718161316.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220726102515.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718164043.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718170235.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718213059.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718220419.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220718222101.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719100039.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719100740.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719101222.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719102013.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719102224.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220726102657.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719102533.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719102626.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719104633.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719113036.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719141337.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719144449.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719145542.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719150331.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719152923.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719154443.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719161550.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719162013.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220726102745.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719164523.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719164758.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719165349.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719180307.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719191636.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719202007.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719205348.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719205658.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220719205717.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220721163836.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220722155512.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220722160949.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220722161213.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220722164834.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220722165723.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723110523.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723112349.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723113143.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723114317.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723115459.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723121621.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723121906.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723122209.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723125410.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723125825.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723130619.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723143531.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723163113.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723164241.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723164736.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723165053.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723165336.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723170831.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723171317.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723171853.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723172319.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723173535.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723180038.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723180408.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723180901.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723181441.png">
<meta property="og:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723182413.png">
<meta property="article:published_time" content="2022-02-06T03:02:33.000Z">
<meta property="article:modified_time" content="2022-07-26T08:33:53.620Z">
<meta property="article:author" content="李旭">
<meta property="article:tag" content="RS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/EverestLi/images/main/20220723152202.png">

<link rel="canonical" href="http://example.com/2022/02/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>推荐系统技术综述 | Matrix</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Matrix</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/02/06/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="李旭">
      <meta itemprop="description" content="学习记录。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Matrix">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          推荐系统技术综述
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-02-06 11:02:33" itemprop="dateCreated datePublished" datetime="2022-02-06T11:02:33+08:00">2022-02-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-07-26 16:33:53" itemprop="dateModified" datetime="2022-07-26T16:33:53+08:00">2022-07-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>《深度学习推荐系统》学习笔记，系统的梳理经典模型、深度学习模型、Embedding技术、系统工程、工程实现和评估。</p>
<span id="more"></span>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723152202.png" alt=""></p>
<h1 id="经典推荐模型"><a href="#经典推荐模型" class="headerlink" title="经典推荐模型"></a>经典推荐模型</h1><h2 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h2><p>2003年，Amazon发表Amazon.com Recommenders Item-to-Item Collaborative Filtering提出，在之后的很长一段时间中协同过滤都是主流的推荐模型。</p>
<h3 id="UserCF"><a href="#UserCF" class="headerlink" title="UserCF"></a>UserCF</h3><p>核心思想是用有向图表示用户和商品，图的边通过设置不同的值来表示用户对商品的喜欢程度，为了方便计算要把图转换成共现矩阵，在判断是否向用户推荐某个商品之前要先找到用该用户兴趣相似的n个用户，综合相似用户对该商品的平均评价得出该用户对该商品的评价，若是正面的则进行推荐，否则不推荐。主要的问题是用户相似度计算和最终结果排序。</p>
<p>在共现矩阵中行向量代表用户的向量，计算用户的相似度就是计算向量间的相似度。最简单的是余弦相似度，衡量两个向量之间的夹角大小，夹角越小，余弦相似度越大，用户越相似。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716162049.png" alt=""></p>
<p>第二种是皮尔逊相关系数，通过单个用户对某商品的评价减去该用户对所有商品的平均评价，减小了用户评分的偏差。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180149313.png" alt="image-20220308180149313"></p>
<p>基于以上思路也可以引入物品平均分，减少物品评分的偏差。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180201157.png" alt="image-20220308180201157"></p>
<p>找出相似用户之后通过用户相似度和相似用户的评价加权平均作为目标用户的评价。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308180216076.png" alt="image-20220308180216076"></p>
<p>在现实的场景中用户的数量要远远大于商品的数量，并且会更快速的增长，UserCF需要维护用户的相似度矩阵以便快速找的相似用户，但相似度矩阵的存储开销很大，在线系统难以承受。用户的历史数据往往也非常稀疏，找到相似用户的准确度非常低，不适用于低频应用。</p>
<h3 id="ItemCF"><a href="#ItemCF" class="headerlink" title="ItemCF"></a>ItemCF</h3><p>基于物品相似度的协同过滤，解决了UserCF的问题。在共现矩阵中用列向量表示商品的向量，通过计算列向量直接的相似度来计算物品的相似度。首先根据用户喜欢的商品找到与这些商品相似的商品，然后计算相似商品的相似度，如果一个商品与用户喜欢的多个商品相似，那么这个商品的相似度就是该商品与多个商品相似度的累加。最后根据相似度生成推荐列表。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220308181906910.png" alt="image-20220308181906910"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>UserCF有更强的社交特性，适用于新闻、热点（内容变化快）的推荐。ItemCF适合于兴趣变化稳定的应用，比如电商、视频推荐。协同过滤直观，可解释性强，但是泛化能力较弱，不能将相似性传递，比如A与B相似，B与C相似，但是无法得到A与C相似，这就会导致热门商品有很强的头部效应（与很多商品都有相似性），而尾部商品很少与其他商品产生相似（处理稀疏向量能力弱），导致很少被推荐。为了解决以上问题提出了矩阵分解、引入更多特征等方法。</p>
<h2 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解"></a>矩阵分解</h2><p>2006年矩阵分解在Netflix Prize Challenge中表现突出，开启了矩阵分解的时代。思想是将用户向量和物品向量在同一个向量空间中表示，然后将距离用户进的物品推荐给该用户。找用户向量和物品向量的方法是将共线矩阵分解，将m<em>n的共现矩阵R分解为m\</em>k的用户矩阵U和k*n的物品矩阵V，其中m是用户数量，n是物品数量，k是隐向量，k的取值越小，隐向量包含的信息越少，模型的泛化程度越高（对新样本的适应能力强），k的取值越大，隐向量包含的信息越多，但是模型的泛化程度降低。用户u对物品i的评分为：</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309174159397.png" alt="image-20220309174159397"></p>
<h3 id="分解方法"><a href="#分解方法" class="headerlink" title="分解方法"></a>分解方法</h3><p>矩阵分解的主要方法有三种：特征值分解，只能用于方阵，不适用于分解用户物品矩阵；奇异值分解SVD，要求原始的共现矩阵是稠密的，但是通常情况下用户历史数据比较稀疏，并且复杂度达到了O(mn²)，对于大量数据复杂度无法接受；梯度下降（Gradient Descent），进行矩阵分解的主要方法，目标函数为</p>
<h3 id=""><a href="#" class="headerlink" title=""></a><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309175621479.png" alt="image-20220309175621479"></h3><p>加入正则化项后的目标函数如下，目的是为了减少过拟合现象，正则化项可以减小目标函数的权重，使模型更加稳定。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309175833957.png" alt="image-20220309175833957"></p>
<p>确定好目标函数后对其求偏导，沿梯度的反方向更新参数，重复该过程到训练结束。在完成矩阵分解以后，可以通过某用户向量和所有物品向量做内积计算出该用户对所有物品的评分，然后依序进行推荐。相比协同过滤，矩阵分解的隐向量是根据全局信息产生的，所以有更强的泛化能力，可以预测任何用户对任何物品的评分。</p>
<h3 id="消除偏差"><a href="#消除偏差" class="headerlink" title="消除偏差"></a>消除偏差</h3><p>由于不同用户的评分标准不同，所以在打分时存在偏差，解决办法是在矩阵分解时加入偏差向量</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309181114489.png" alt="image-20220309181114489"></p>
<p>目标函数变为</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220309181137010.png" alt="image-20220309181137010"></p>
<p>通过加入偏差项后，更能反映用户的真实态度，从而避免推荐的偏差。</p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>矩阵分解的泛化能力强，一定程度解决了数据稀疏问题，同时空间复杂度低（O((n+m)·k)），只需要存储用户和物品的隐向量，矩阵分解的结果是向量，更便于与其他特征和深度学习网络结合。但是不方便加入用户、物品和上下文相关的信息，丧失了一些利用有效信息的机会，同时在缺乏用户历史行为是，无法进行有效的推荐。随后提出的逻辑回归模型和因子分解机等使这些问题得到解决。</p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归根据多种特征生成推荐结果，将问题看成一个分类问题，通过预测正样本的概率对物品进行排序。首先将各种特征信息转换成数值型特征向量，然后确定好优化目标，利用已有样本数据进行训练，确定好模型参数，训练完成后将特征向量输入模型便可以得到用户“点击“的概率，最后根据“点击“的概率排序生成推荐列表。</p>
<p>模型的推断过程为：将特征向量x1，x2…xn作为模型的输入，并给每个特征向量赋予权重w1，w2…wn来表示重要性差异，对个特征进行加权求和得到x<sup>T</sup>w，将x<sup>T</sup>w输入sigmoid函数得到最后的“点击率”，数学形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310204002189.png" alt="image-20220310204002189"></p>
<p>预测结果为正样本和负样本的概率为</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310204819943.png" alt="image-20220310204819943"></p>
<p>由极大似然估计的原理写出逻辑回归额目标函数</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205113107.png" alt="image-20220310205113107"></p>
<p>由于连乘形式不便于求导，故在上式两侧取log，并乘以系数-(1/m)，将最大值问题转换成求极小值的问题</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205324107.png" alt="image-20220310205324107"></p>
<p>然后对每个参数求偏导，到到梯度的方向</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205421359.png" alt="image-20220310205421359"></p>
<p>最后更新参数</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310205512459.png" alt="image-20220310205512459"></p>
<p>逻辑回归具有数学含以上的支撑，可解释性强，并且易于并行化、模型简单、训练开销小。但是表达能力不强（无法拟合复杂函数），无法进行特征交叉、特征筛选等，会造成信息的损失。</p>
<h2 id="POLY2"><a href="#POLY2" class="headerlink" title="POLY2"></a>POLY2</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103813814.png" alt="image-20220312103813814"></p>
<p>使用逻辑回归对单一特征做加权，没有进行特征交叉生成高维组合特征的能力，可能得出“辛普森悖论”的错误，POLY2模型通过对特征进行暴力组合来解决这个问题，数学形式为</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310221917734.png" alt="image-20220310221917734"></p>
<p>该模型对所有特征进行两两交叉，并对所有的特征组合赋予权重，一定程度上解决了特征组合的问题，但大多数据都为稀疏数据，POLY2会使数据更加稀疏无法收敛，并且模型的参数从n变成n²，更不好训练。</p>
<h2 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103823700.png" alt="image-20220312103823700"></p>
<p>为了解决POLY2的问题，FM模型在2010年提出，相比POLY2，FM用两个向量的内积取代了单一的权重系数，相当于为每个特征学习了一个隐权重向量，与矩阵分解相比，从单一的用户、物品隐向量扩展到了所有特征上。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220310223257498.png" alt="image-20220310223257498"></p>
<p>将参数数量从n²减少到了nk，降低了训练开销。由于POLY2两个向量共用一个权重，只有同时出现这两个向量的样本时才能更新组合特征的权重，而FM每个特征向量都有一个隐向量，只要特征组合中的一个特征向量在样本中出现，就可以更新这个特征向量的隐向量，即使在样本中没有出现过的特征组合也可以计算组合权重，这使得FM的泛化能力大大提高。因为FM使用梯度下降进行学习，具有实时性和灵活性的特点。</p>
<h2 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312103835285.png" alt="image-20220312103835285"></p>
<p>2015年基于FM提出，引入了特征域感知概念，使模型表达能力更强，数学形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312095422634.png" alt="image-20220312095422634"></p>
<p>与FM的区别在于隐向量由原来的W<sub>j<sub>1</sub>&lt;/sub&gt;变成了W<sub>j<sub>1</sub>,f<sub>2</sub>&lt;/sub&gt;，表示每个特征对应的不再是唯一一个隐向量，而是一组隐向量，做交叉时从自己一组隐向量中选择一个与另一个特征的域对应的隐向量。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312101802053.png" alt="image-20220312101802053"></p>
<p>以上是三个特征域各有一个特征，当ESPN与NIKE交叉时，ESPN的选择的隐向量就是W<sub>ESPN,NIKE</sub>，当ESPN与Male交叉时，ESPN的选择的隐向量就是W<sub>ESPN,Male</sub>，如果使用FM的方法，无论ESPN与哪个特征交叉，隐向量都是W<sub>ESPN</sub>。</p>
<p>相比FM，FFM的复杂度变为kn²，但是引入了更多有价值的信息，应用时需要在效果和投入之间权衡。</p>
<h2 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT+LR"></a>GBDT+LR</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312104749343.png" alt="image-20220312104749343"></p>
<p>GBDT负责对特征进行筛选和组合，然后将生成的离散特征输入LR进行预测，GBDT和LR独立训练，不存在复杂的梯度回传问题。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312105705554.png" alt="image-20220312105705554"></p>
<p>GBDT是决策树组成的森林，预测的方式是把所有子树的结果加起来，通过逐一生成决策树的方式生成整个树林，在生成下一个决策树之前先计算之前生成的所有决策树的和与目标函数的差，然后生成一个新的决策树，使所有决策树的和与目标函数越接近越好。因为GBDT是由多颗回归树组成，回归树中每个节点的分离都是自然的特征选择的过程，同时多层节点的结构对特征进行了有效的自动组合，高效解决了特征选择和特征组合的问题。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312112146955.png" alt="image-20220312112146955"></p>
<p>以上的GBDT有3个子树组成，每个子树有4个叶节点，即每个子树输出4个元素的向量，共输出一个12个元素的向量。决策树的深度决定特征交叉的阶数，如果深度为4则是进行三阶特征组合，但是GBDT容易过拟合，并且会丢失大量特征的数值信息。</p>
<p>GBDT+LR的提出，使得特征工程可以由一个独立的模型完成，真正实现了End to End训练。</p>
<h2 id="LS-PLM"><a href="#LS-PLM" class="headerlink" title="LS-PLM"></a>LS-PLM</h2><p>在逻辑回归的基础上加入分片（分类）思想，比如对女性受众的推荐，不希望男性样本的干扰，先将样本分类然后在进行逻辑回归，公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220312195738770.png" alt="image-20220312195738770"></p>
<p>m表示分片数，当m为1时就是普通的逻辑回归，m越大模型的拟合能力越强，模型的规模也会更大，更难训练。</p>
<p>LS-PLM具有端到端的非线性学习能力，并且在建模时引入了L1和L2,1范数，训练处的模型具有较高的稀疏度，部署更加轻量化，在线推荐效率也更高。也可以将LS-PLM看做是加入了Attention的三层神经网络模型，输入层是样本的特征向量，中间层是m个分片（m个神经元），输出层由单一神经元，Attention在中间层和输出层之间。</p>
<h1 id="深度学习推荐模型"><a href="#深度学习推荐模型" class="headerlink" title="深度学习推荐模型"></a>深度学习推荐模型</h1><p>与传统的机器学习模型相比，深度学习模型的表达能力更强，能够挖掘出更多数据中潜藏的模式；深度学习的模型结构非常灵活，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。</p>
<h2 id="改变神经网络复杂程度"><a href="#改变神经网络复杂程度" class="headerlink" title="改变神经网络复杂程度"></a>改变神经网络复杂程度</h2><h3 id="AutoRec"><a href="#AutoRec" class="headerlink" title="AutoRec"></a>AutoRec</h3><p>利用协同过滤中的共现矩阵完成物品向量或用户向量的自编码，再利用自编码的结果得到用户对物品的预估评分，进行排序。自编码器的目标函数如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313110753122.png" alt="image-20220313110753122"></p>
<p>r为输出向量，目的是找到一个重建函数h使得输入和h的差越小越好，就相当于用一个函数表示了一组数据，一般重建函数的参数数量远小于输入向量的维度数量，等于完成了数据压缩和降维工作。由于经过了自编码器的泛化，也具备了一定的缺失维度的预测能力。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313111741551.png" alt="image-20220313111741551"></p>
<p>AutpRec模型是一个三层神经网络，利用梯度反向传播训练，V是输入层到隐藏层的参数矩阵，W是隐藏层到输出层的参数矩阵，模型的具体形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313112005607.png" alt="image-20220313112005607"></p>
<p>为了防止过拟合加入L2正则化，AutoRec目标函数的具体形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313112106849.png" alt="image-20220313112106849"></p>
<p>以基于物品的AutoRec为例，训练好网络后如果想预测用户u对物品i的评分，只需要输入物品i的评分向量，模型会输出所有用户对i的评分预测，找到用户u的评分即可，如果想得到用户u的推荐列表，对每个物品的评价向量重复以上过程，然后对评分排序即可。</p>
<p>相比I-AutoRec（基于物品），U-AutoRec（基于用户）只需输入一次用户向量就能获得用户对所有物品的评分，但是用户向量的稀疏性可能会影响模型的效果。AutoRec模型使用一个单隐层，具有一定泛化和表达的能力，但是表达能力有限，算是深度学习推荐系统的开端。</p>
<h3 id="Deep-Crossing"><a href="#Deep-Crossing" class="headerlink" title="Deep Crossing"></a>Deep Crossing</h3><p>由微软提出，主要用于搜索广告推荐，特征分为可被处理成one-hot或multi-hot向量的类别型特征、数值型特征、需要进一步处理的特征，具体如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313131344283.png" alt="image-20220313131344283"></p>
<p>Deep Crossing模型的网络结构有四层，包括Embedding层、Stacking层、Multiple Residual Units层、Scoring层</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313131555230.png" alt="image-20220313131555230"></p>
<p>Embedding层：将稀疏的类别特征转换成稠密的Embedding向量，Embedding层以全连接层结构为主。</p>
<p>Stacking层：把不同的Embedding特征和数值特征拼接在一起，形成包含全部特征的特征向量，该层也叫连接层。</p>
<p>Multiple Residual Units层：主要结构是多层感知机，使用了多层残差网络，能够对特征向量各个维度进行成分的交叉组合，使模型能够获得更多非线性特征和组合特征的信息，在表达能力上大大增强。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313133304540.png" alt="image-20220313133304540"></p>
<p>将输入加到输出上作为最终的输出，中间的网络在拟合输出和输入直接的残差（x0-xi）。残差网络减少了过拟合现象，使用ReLU替代sigmoid解决了反向传播中的梯度消失问题，输入向量短路相当于直接把梯度传递到下一层，使得网络收敛速度更快。</p>
<p>Scoring层：输出层，拟合优化目标，对于CTR预估二分类问题使用逻辑回归模型，对于图像分类多分类问题采用softmax模型。</p>
<p>Deep Crossing模型是End to End的，原特征经Embedding后输入神经网络层，将全部特征交叉任务交给模型，并且可以通过调整神经网络的深度进行特征间的深度交叉，即有多阶特征交叉能力。</p>
<h2 id="改变特征交叉方式"><a href="#改变特征交叉方式" class="headerlink" title="改变特征交叉方式"></a>改变特征交叉方式</h2><h3 id="NeuralCF"><a href="#NeuralCF" class="headerlink" title="NeuralCF"></a>NeuralCF</h3><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313140757732.png" alt="image-20220313140757732"></p>
<p>NeuralCF使用多层神经网络+输出层替代矩阵分解模型中简单的内积操作，一是让用户向量和物品向量做更充分的交叉，得到更多有价值的特征组合信息；二是引入更多的非线性特征，让模型表达能力更强。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313141634399.png" alt="image-20220313141634399"></p>
<p>用户和物品向量的互操作层可以被任意的互操作形式所替代，这就是所谓的“广义矩阵分解”，甚至可以将不同的互操作网络得到的特征向量拼起来，交给输出层进行目标拟合，这使模型有了更强的特征组合和非线性能力。</p>
<p>NeuralCF提出的是一个模型框架，基于用户向量和物品向量的Embedding层，利用不同的互操作层进行特征的交叉组合，按需要调整模型的复杂度。由于是基于协同过滤的思想，只有用户特征和物品特征，并没有引入更多其他类型的特征，浪费了其他有价值的信息。</p>
<h3 id="PNN"><a href="#PNN" class="headerlink" title="PNN"></a>PNN</h3><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313144640704.png" alt="image-20220313144640704"></p>
<p>和Deep Crossing模型相比，用乘积层代替了Stacking层，Embedding向量不再是简单的拼接，而是用Product进行两两相乘，可以获取更多特征间的交叉信息。乘积层又分为z部分（对各特征向量进行线性拼接）和p部分（对各特征向量进行乘积操作），乘积操作又分为内乘积操作（Inner Product-based Neural Network）和外乘积操作（Outer Product-based Neural Network）,定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313145940140.png" alt="image-20220313145940140"></p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/image-20220313145950401.png" alt="image-20220313145950401"></p>
<p>外积操作是对输入特征向量各维度进行两两交叉，生成一个M×M的方阵，这会导致复杂度提高，为了解决这个问题将外积互操作的结果叠加，最后转换成向量先相加再做外积的方式，定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220621222418.png" alt=""></p>
<p>相当于让所有Embedding向量通过一个平均池化层之后在进行外积互操作，操作的前提是个特征对应的维度有类似的含义，否则将不同含义的维度平均起来会模糊很多有价值的信息。</p>
<p>PNN的结果重点提出Embedding向量之间的交叉方式是多样化的，内积和外积操作让模型可以获得更多特征的交叉信息。但是为了训练效率，外积操作进行了大量简化，并且对特征进行无差别交叉，忽略了原始特征中一些有价值的信息。</p>
<h2 id="组合模型"><a href="#组合模型" class="headerlink" title="组合模型"></a>组合模型</h2><h3 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h3><p>将记忆能力强的简单模型和泛化能力强的深度学习模型结合，使模型同事具有记忆能力和泛化能力。</p>
<p>记忆能力：强特征对模型的影响很大，多层神经网络因为特征处理复杂，强特征对模型的影响也相对较少。</p>
<p>泛化能力：模型通过传递特征的相关性，以发现稀疏特征和从未出现过的稀有特征与最终标签的相关性。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716162946.png" alt=""></p>
<p>把单输入层的Wide部分与由Embedding层和多隐层组成的Deep部分连接起来，一起输入最终的输入层，利用逻辑回归组合起来，形成统一的模型。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716163428.png" alt=""></p>
<p>Googel Play实际应用中，Deep部分的输入是全部的特征，Wide部分的输入仅仅是两个特征，符合业务场景。Wide部分的定义如下：</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716163839.png" alt=""></p>
<p>c<sub>ki</sub>是一个布尔变量，表示第i个特征是否属于特征组合k，x<sub>i</sub>表示第i个特征向量的值。</p>
<h3 id="Deep-amp-Cross-DCN"><a href="#Deep-amp-Cross-DCN" class="headerlink" title="Deep&amp;Cross(DCN)"></a>Deep&amp;Cross(DCN)</h3><p>使用Cross网络替代Wide&amp;Deep中Wide的部分。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716165503.png" alt=""></p>
<p>Cross网络使用多层交叉层对输入向量进行特征交叉，第l+1层的输出向量如下：</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716165650.png" alt=""></p>
<p>类似于PNN模型的外积操作，在此基础上增加了权重向量，原输入向量和偏置向量。</p>
<p>交叉层的操作如下：</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716170027.png" alt=""></p>
<p>每层只增加一个n维的权重向量w<sub>l</sub>，并且保留了输入向量，因此输入与输出的变化不会特别明显。完成了特征的自动化交叉。</p>
<h2 id="FM模型的深度学习演化版本"><a href="#FM模型的深度学习演化版本" class="headerlink" title="FM模型的深度学习演化版本"></a>FM模型的深度学习演化版本</h2><h3 id="FNN"><a href="#FNN" class="headerlink" title="FNN"></a>FNN</h3><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716172722.png" alt=""></p>
<p>用FM模型训练号的各特征隐向量初始化Embedding层的参数，使网络的收敛过程更快。</p>
<p>Embedding层收敛慢一是参数量巨大，占网络权重的绝大部分，二是梯度下降过程中只有与非零特征向量的Embedding层权重会更新，实际上存在很多零特征，进一步降低了Embedding层收敛的速度。</p>
<p>上图中虽然FM中的参数指向了Embedding层各神经元，但实际上是初始化Embedding神经元与输入神经元之间的连接权重。假设FM隐向量的纬度为m，第i各特征域的第k维特征的隐向量是</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220716174108.png" alt=""></p>
<p>那么隐向量的第l维v<sup>l</sup><sub>i,k</sub>就会成为连接输入神经元k和Embedding神经元l之间的连接权重初始化值。</p>
<p>FM中没有对特征域进行区分，但在FNN中进行了区分，因此每个特征域有对应的Embedding层，并且每个特征域Embedding的维度都应与FM隐向量维度保持一致。为Embedding预训练提供了借鉴思路。</p>
<h3 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h3><p>将FM的模型结构与Wide&amp;Deep模型结合，用FM替换原来的Wide部分，加强浅层网络部分特征组合的能力。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718153130.png" alt=""></p>
<p>左边的FM和右边的深度神经网络共享相同的Embedding层，FM部分对不同的特征域的Embedding进行两两交叉，也就是将Embedding向量当做原FM中的特征隐向量。最后将FM的输出和Deep部分的输出一同输入最后的输出层。</p>
<h3 id="NFM"><a href="#NFM" class="headerlink" title="NFM"></a>NFM</h3><p>使用深度神经网络解决FM表达能力问题，用一个表达能力更强，由深度学习实现的函数代替原FM中二阶隐向量内积部分，如下图</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718155048.png" style="zoom:50%;" /></p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718155248.png" alt=""></p>
<p>NFM的特点是在Embedding层和多层神经网络之间加入特征交叉池化层，具体操作如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718155500.png" alt=""></p>
<p>中间为元素积操作（长度相同向量对应维相乘得到元素积向量），元素积操作后对交叉特征向量取和，得到池化层的输出向量，然后输入上层的多层全连接神经网络进行进一步交叉。NFM的结构图省略了一阶部分，如果把一阶部分视为一个线性模型，那么NFM的架构也可以视为Wide&amp;Deep模型的进化，相比原模型在Deep部分加入了特征交叉池化层，加强了特征交叉。</p>
<h2 id="注意力机制与推荐模型的结合"><a href="#注意力机制与推荐模型的结合" class="headerlink" title="注意力机制与推荐模型的结合"></a>注意力机制与推荐模型的结合</h2><h3 id="AFM"><a href="#AFM" class="headerlink" title="AFM"></a>AFM</h3><p>在NFM的特征交叉池化层加入注意力机制，具体模型结构如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718160407.png" alt=""></p>
<p>特征交叉过程同样采用了元素积操作，如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718161238.png" alt=""></p>
<p>加入注意力得分后的池化过程如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718161316.png" alt=""></p>
<p>a<sub>ij</sub>k可以用一个权重参数来表示，但为了防止交叉特征数据稀疏问题带来的权重参数难以收敛，AFM使用一个全连接层加softmax输出层的注意力网络来生成注意力得分，数学形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220726102515.png" alt=""></p>
<p>要学习的参数是特征交叉层到注意力网络全连接层的权重矩阵W，偏置向量b，以及全连接层到softmax输出层的权重向量h，注意力网络将与整个模型一起参与梯度反向传播的学习过程，得到最终的权重参数。</p>
<h3 id="DIN"><a href="#DIN" class="headerlink" title="DIN"></a>DIN</h3><p>由阿里巴巴提出，应用场景是电商广告推荐，模型的输入特征分为用户特征组和广告特征组，两者都包含商品id和商铺id。用户特征里的商品和店铺id是用户点过的集合，广告特征里的商品id和店铺id是广告对应的商品id和店铺id。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718164043.png" alt=""></p>
<p>在原来的基础模型中，用户特征组中的商品序列和商铺序列没有区分重要程度，也和广告特征中的商品id没有关系。</p>
<p>加入注意力机制的DIN模型，利用候选商品和历史行为商品的之间的相关性计算出一个权重，表达式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718170235.png" alt=""></p>
<p>V<sub>u</sub>是用户的Embedding向量，V<sub>a</sub>是候选广告商品的Embedding向量，V<sub>i</sub>是用户u的第i次行为的Embedding向量（此次行为浏览的商品或店铺的Embedding向量），V<sub>u</sub>从过去的V<sub>i</sub>的加和变成了加权和，V<sub>i</sub>的权重又V<sub>i</sub>与V<sub>a</sub>的关系决定，既注意力函数g。g由一个激活单元构成，输入层是两个Enbedding向量，经过元素减操作后，与原Embedding向量一同连接后形成全连接层的输入，最后通过神经单元输出层生成注意力得分。并且商铺id只跟用户历史行为中的商铺id序列发生作用，商品id同理，因为注意力轻重更应该由同类信息的相关性决定。</p>
<h2 id="序列模型与推荐模型的结合"><a href="#序列模型与推荐模型的结合" class="headerlink" title="序列模型与推荐模型的结合"></a>序列模型与推荐模型的结合</h2><h3 id="DIEN"><a href="#DIEN" class="headerlink" title="DIEN"></a>DIEN</h3><p>对DIN模型进行改进，引入“序列”信息，创新点在于“兴趣进化网络”。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718213059.png" alt=""></p>
<p>行为序列层：把原始的id类行为序列转换成Embedding行为序列，结构与普通Embedding层一致。</p>
<p>兴趣抽取层：通过模拟用户兴趣迁移过程，抽取用户兴趣。基本结构是GRU网络，解决了RNN梯度消失问题，与LSTM相比参数量更少，收敛速度更快。GRU单元的公式定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718220419.png" alt=""></p>
<p>σ是Sigmoid激活函数，。是元素积炒作，W<sup>x</sup>,U<sup>x</sup>是6个需要学习的参数矩阵，i<sub>t</sub>是输入状态向量，也就是个行为Embedding向量b(t)，h<sub>t</sub>是GRU网络中第t个隐状态向量。</p>
<p>兴趣进化层：在兴趣抽取的基础上加入注意力机制，模拟与当前目标广告相关的兴趣进化过程。通过引入AUGRU（基于注意力更新门的GRU）结构，具体形式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220718222101.png" alt=""></p>
<h2 id="强化学习与推荐模型的结合"><a href="#强化学习与推荐模型的结合" class="headerlink" title="强化学习与推荐模型的结合"></a>强化学习与推荐模型的结合</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719100039.png" alt=""></p>
<p>智能体：推荐系统本身，包括推荐模型、探索策略，以及相关的数据存储。</p>
<p>环境：由新闻网站或App、用户组成的整个推荐系统外部环境，在环境中，用户接收推荐的结果并做出相应反馈。</p>
<p>行动：对新闻推荐系统来说，行动指推荐系统进行新闻排序后推送给用户的动作。</p>
<p>反馈：用户收到推荐结果后，进行正向或负向的反馈。</p>
<p>状态：对环境及自身当前所处具体情况的刻画，可以看做已收到的、可用于训练的所有数据的集合。</p>
<p>迭代过程：</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719100740.png" alt=""></p>
<h3 id="DRN"><a href="#DRN" class="headerlink" title="DRN"></a>DRN</h3><p>DRN中的智能体是DQN，Q是Quality，指通过对行动进行质量评估，得到行动的效用得分，以此进行行动决策。DQN的网络结构如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719101222.png" alt=""></p>
<p>在特征工程中套用强化学习状态向量和行为向量的概念，把用户特征和环境特征归为状态向量，把用户新闻交叉特征和新闻特征归为行动向量。用户特征和环境特征经过左侧神经网络拟合生成价值得分V，利用状态向量和行动向量生成优势得分A，最后将两者综合起来得到最后的质量得分Q。</p>
<p>DRN的学习过程如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719102013.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719102224.png" alt=""></p>
<p>主更新可以理解为利用历史数据的重新训练，模型微调使用下面的竞争梯度下降算法。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220726102657.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719102533.png" alt=""></p>
<p>产生随机扰动的公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719102626.png" alt=""></p>
<p>α是探索因子，决定探索力度的大小。rand(-1,1)是一个[-1,1]之间的随机数。</p>
<h1 id="Embedding技术"><a href="#Embedding技术" class="headerlink" title="Embedding技术"></a>Embedding技术</h1><h2 id="什么是Enbedding"><a href="#什么是Enbedding" class="headerlink" title="什么是Enbedding"></a>什么是Enbedding</h2><p>Embedding就是用一个低维稠密向量表示一个对象，能够表达相应对象的某些特征，同时向量之间的距离反应了对象之间的相似性。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719104633.png" alt=""></p>
<p>Embedding技术对深度学习推荐系统的重要性如下：</p>
<p>（1）推荐场景中大量使用one-hot、id型特征进行编码，导致样本特征向量极度稀疏，而深度学习不利于处理稀疏特征向量，因此需要Embedding技术将高维稀疏向量转换成稠密低维向量。</p>
<p>（2）Embedding本身就是极其重要的特征向量。Embedding的表达能力强，几乎可以引入任何信息进行编码。</p>
<p>（3）Embedding对物品、用户相似度的计算是常用的推荐系统召回技术。</p>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>是一个对“词”向量表达的模型，训练时需要准备一组句子组成的语料库，假设每个词都跟其相邻的词的关系最密切，</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719113036.png" alt=""></p>
<p>CBOW模型输入是w<sub>t</sub>周边的词，预测的输出是w<sub>t</sub>，Skip-gram相反，但是效果较好，以下以Skip-gram为框架介绍。</p>
<p>首先生成训练样本，选取一个长度为2c+1（目标词前后各选c个词）的滑动窗口，从语料库中抽取一个句子，将滑动窗口由左到右滑动，每移动一次，窗口中的词组就形成一个训练样本。</p>
<p>因为每个词w<sub>t</sub>都决定了相邻词w<sub>t+j</sub>，基于极大似然估计的方法（已知样本结果，反推最可能导致这些样本结果的模型参数），希望所有样本的条件概率p(w<sub>t+j</sub>|w<sub>t</sub>)（w<sub>t+j</sub>发生之后w<sub>t</sub>发生的概率）之积最大，故目标函数如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719141337.png" alt=""></p>
<p>p(w<sub>t+j</sub>|w<sub>t</sub>)使用softmax函数，公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719144449.png" alt=""></p>
<p>w<sub>o</sub>代表w<sub>t+j</sub>，称为输出词，w<sub>I</sub>代表w<sub>t</sub>，称为输入词，v<sub>w</sub>是用来表示词w的向量，v<sup>T</sup>v表示两个词向量的内积距离，也就是两个词的接近程度。需要注意V<sub>w<sub>o</sub>&lt;/sub&gt;和V<sub>w<sub>I</sub>&lt;/sub&gt;分别是词w的输出向量表达和输入向量表达，二者的向量表达并不在一个向量空间内。上面公式可以转换成下面的神经网络结构</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719145542.png" alt=""></p>
<p>输入向量表达是输出层到隐层的权重矩阵W<sub>V×N</sub>，而输出向量表达就是隐层到输出层的权重矩阵W’<sub>N×V</sub>。获得了输入向量矩阵W<sub>V×N</sub>后，其中每一行对应的权重向量就是通常意义上的“词向量”。于是这个权重矩阵就转换成了Word2vec的查找表，如下图所示</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719150331.png" alt=""></p>
<p>假设语料库中的词的数量为10000，就意味着输出层神经元有10000个，训练过程中无法承受如此大的计算量，所以在实际训练时通常采用负采样训练方法。优化目标从一个多分类问题退化成了一个近似二分类问题，公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719152923.png" alt=""></p>
<p>v‘<sub>w<sub>o</sub>&lt;/sub&gt;是输出词向量（正样本），h是隐层向量，W<sub>neg</sub>是负样本集合，v‘<sub>w<sub>j</sub>&lt;/sub&gt;是负样本词向量，由于负样本集合的大小非常有限，计算复杂度至少可以缩小为原来的1/1000。</p>
<h2 id="Item2vec"><a href="#Item2vec" class="headerlink" title="Item2vec"></a>Item2vec</h2><p>对用户购买序列中的一个商品，用户观看序列中的一个电影进行Embedding的方法。</p>
<p>假设Item2vec中一个长度为K的用户历史记录为w<sub>1</sub>…w<sub>t</sub>，则优化目标如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719154443.png" alt=""></p>
<p>相比Word2vec，Item2vec摒弃了时间窗口的概念，认为序列中任意两个物品都相关，目标函数中是两两物品的对数概率的和，而不仅是时间窗口内物品的对数概率之和。Item2vec后面的训练过程与Word2vec一致。</p>
<p>广义上的Item2vec模型是物品向量化方法的统称，可以利用不同的深度学习网络结构对物品特征进行Embedding化。因为只能利用序列型数据，对网络化数据无能为力。</p>
<h2 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h2><p>解决上面两种方法无法处理网络化数据的问题，是一种对图结构中的节点进行Embedding编码的方法，最终生成的节点Embedding向量一般包含图的结构信息及附近节点的局部相似性信息。</p>
<h2 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h2><p>主要思想是在由物品组成的图结构上随机游走，产生大量物品序列，然后将这些物品序列作为训练样本输入Word2vec进行训练，得到物品的Embedding，可以看做连接序列Embedding和Graph Embedding的过渡方法，算法流程如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719161550.png" style="zoom:50%;" /></p>
<p>对于有向有权的物品关系图，从节点v<sub>i</sub>跳转到节点v<sub>j</sub>的概率定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719162013.png" alt=""></p>
<p>ε是物品关系图中所有边的集合，N<sub>+</sub>(v<sub>i</sub>)是v<sub>i</sub>所有出边的集合，M<sub>ij</sub>是节点v<sub>i</sub>到节点v<sub>j</sub>边的权重，即跳转概率就是跳转边的权重占所有相关出边权重之和的比例。</p>
<h2 id="Node2vec"><a href="#Node2vec" class="headerlink" title="Node2vec"></a>Node2vec</h2><p>在DeepWalk基础上调整随机游走权重，使Graph Embedding结果更倾向于体现网络的同质性或结构性。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220726102745.png" alt=""></p>
<p>同质性是指距离相近节点的Embedding应尽量相似，结构性是指结构上相似的节点的Embedding应尽量近似。为了表达结构性，需要让随机游走过程更倾向于BFS，为了表达同质性，需要让随机游走更倾向于DFS，BFS和DFS的倾向性由节点间的跳转概率来控制。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719164523.png" alt=""></p>
<p>上图为Node2vec算法从节点t跳到节点v，再从节点v跳到下一个节点x的概率，概率为</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719164758.png" alt=""></p>
<p>其中w<sub>vx</sub>是边vx的权重，α部分的定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719165349.png" alt=""></p>
<p>d<sub>tx</sub>是从节点t到节点x的距离，p称为返回参数，p越小，随机游走回节点t的可能性就越大，Neode2vec更注重表达网络的结构性。q称为进出参数，q越小随机游走到远方节点的可能性越大，Neode2vec更注重表达网络的同质性。</p>
<p>在推荐系统中同质性相同的物品很可能是通品类、同属性，或者经常被一同购买的商品，而结构性相同的物品则是各品类的爆款、各品类的最佳凑单商品等拥有类似趋势或结构属性的商品。甚至可以把生成的偏向结构性和偏向同质性的Embedding结果共同输入后续的深度学习网络。</p>
<h2 id="EGES"><a href="#EGES" class="headerlink" title="EGES"></a>EGES</h2><p>在DeepWalk生成的Graph Embedding基础上引入补充信息，可以使冷启动物品获得合理的初始Embedding。可以把基于知识图谱生成的物品向量作为补偿信息Embedding向量，也可以有多个补充信息。融合一个物品的多个Embedding向量最简单的方法是在深度神经网络中加入平均池化层，为了防止简单的平均池化导致有效Embedding信息的丢失，阿里巴巴对每个Embedding加上了权重，如下图</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719180307.png" alt=""></p>
<p>隐层表达对不同Embedding进行加权平均操作，然后将结果输入softmax层，通过梯度反向传播，求得每个Embedding的权重a<sub>j</sub>。在实际模型中采用e<sup>a<sub>j</sub></sup>作为权重，一是避免权重为0，二是因为e<sup>a<sub>j</sub></sup>在梯度下降过程中有良好的数学性质。</p>
<h2 id="Embedding与深度学习推荐系统的结合"><a href="#Embedding与深度学习推荐系统的结合" class="headerlink" title="Embedding与深度学习推荐系统的结合"></a>Embedding与深度学习推荐系统的结合</h2><p>（1）在深度学习网络中作为Embedding层，完成从高维稀疏特征向量到低维稠密特征向量的转换。</p>
<p>（2）作为预训练的Embedding特征向量，与其他特征向量连接后，一同输入深度学习网络进行训练。但是Embedding层输入向量的维度往往很大，会拖慢神经网络的收敛速度，所以更多使用预训练Embedding层的方式代替。预训练的方法可以是FNN中将FM模型训练得到的各特征隐向量作为Embedding层的初始化权重，可以是任何异构模型（如GBDT+LR中的GBDT部分），可以使用不同的训练频率更新Embedding模型和神经网络模型，使得训练开销和模型效果最优。</p>
<p>（3）通过计算用户和物品的Embedding相似度，Embedding可以直接作为推荐系统的召回层或者召回策略之一。YouTube利用Embedding进行候选物品召回的方法如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719191636.png" alt=""></p>
<p>其中模型的输入层特征全部都是用户相关特征，模型的输出层是softmax层，预测目标是用户看了哪个视频，输出向量是用户看每一个视频的概率分布，输出向量的每一维对应了一个视频，该维对应的softmax层列向量就是物品Embedding。通过模型的离线训练，可以最终得到每个用户的Embedding和物品的Embedding。模型部署过程中，只需要将用户Embedding和物品Embedding存储到线上内存数据库，通过内积运算再排序的方法得到物品的排序，再通过取序列中TopN的物品即可得到召回的候选集合。再通过相似Embedding快速索引方法，可以更快地召回候选集合。</p>
<p>局部敏感哈希的思想是让相邻的点落入同一个“桶”，在进行最近邻搜索时，仅需要在一个桶内。基于低维空间可以保留高维空间相近距离关系的性质，就可以构造局部敏感哈希“桶”。使用下面哈希函数进行分桶</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719202007.png" alt=""></p>
<p>v是高维空间中k维Embedding向量，x是随机生成的k维映射向量，通过内积操作完成从Embedding向量到一维空间的映射。w是分桶宽度，b是0到w间的一个均匀分布随机变量，避免分桶边界固化。最外面的括号是向下取整操作。</p>
<p>映射操作损失了部分距离信息，如果仅采用一个哈希函数进行分桶，则必然纯在相近点误判的情况，解决方法是采用m个哈希函数同时进行分桶，同时掉进m个哈希函数的同一个桶的两点，是相似点的概率将大大增加。最终生成候选集的时候，不同哈希函数对应桶内的点如果采用与操作则准确率提高，计算开销小，但可能会漏掉一些邻近点。不同哈希函数对应桶内的点如果采用或操作则召回率提高，但是计算开销变大，需要在准确率和召回率之间权衡。</p>
<h1 id="系统工程"><a href="#系统工程" class="headerlink" title="系统工程"></a>系统工程</h1><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>原则：尽可能让特征工程抽取出的一组特征能够保留推荐环境及用户行为过程中的所有有用信息，尽量摒弃冗余信息。</p>
<h3 id="常用特征"><a href="#常用特征" class="headerlink" title="常用特征"></a>常用特征</h3><p>（1）用户行为数据</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719205348.png" alt=""></p>
<p>（2）用户关系，比如通过“关注”“好友关系”连接建立的强关系，也可以是通过“互相点赞”“同做一件事情”建立的软关系。</p>
<p>（3）属性、标签类数据</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719205658.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220719205717.png" alt=""></p>
<p>（4）内容数据，可以看做属性标签型特征的延伸，但是需要通过NLP、CV等提取关键内容特征后，再输入推荐系统。</p>
<p>（5）上下文信息，描述推荐行为产生的场景信息。比如时间、地点、天气等。</p>
<p>（6）统计类特征，通过统计方法计算出的特征。如历史CTR、历史CVR、物品热门程度、物品流行程度等。统计类特征一般是连续型特征，仅需要经过标准化归一化等处理就可以直接输入推荐系统进行训练。</p>
<p>（7）组合特征，将不同特征进行组合后生成的新特征。比如“年龄+性别”组成的人口属性分段特征。</p>
<h3 id="常用特征的处理方法"><a href="#常用特征的处理方法" class="headerlink" title="常用特征的处理方法"></a>常用特征的处理方法</h3><p>（1）连续型特征，用户年龄、统计类特征、物品发布时间、影片播放时长等数值特征。</p>
<p>归一化：目的是统一个特征的量纲，将连续特征归一到[0,1]区间，也可以做0均值归一化，将原始数据集归一化为均值为0、方差为1的数据集。</p>
<p>离散化：通过确定分位数的形式将原来的连续值进行分桶，最终形成离散值的过程。目的是为了防止连续值带来的过拟合现象及特征值分布不均匀的情况。经过离散化处理的连续特征和经过one-hot处理的类别型特征一样，都是以腾正向量的形式输入推荐模型中的。</p>
<p>加非线性函数：直接把原来的特征通过非线性函数做变换，然后把原来的特征及变换后的特征一起加入模型进行训练。目的是更好地捕获特征与优化目标之间的非线性关系，增强模型的非线性表达能力。常用的非线性函数如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220721163836.png" alt=""></p>
<p>（2）类别型特征，用户的历史行为数据、属性标签类数据等。常用的处理方法是使用one-hot编码将其转换成一个数值向量，面对同一个特征域非唯一的类别选择还可以采用multi-hot编码，多个类别选择为1，其余全为0。one-hot和multi-hot编码的为题是特征向量维度过大，特征过于稀疏，容易造成模型钱你和，模型的权重参数过多，导致模型收敛过慢，一般先将类别型特征编码成稠密Embedding向量，再与其他特征组合，形成最终的输入特征向量。</p>
<h2 id="召回策略"><a href="#召回策略" class="headerlink" title="召回策略"></a>召回策略</h2><h3 id="多路召回策略"><a href="#多路召回策略" class="headerlink" title="多路召回策略"></a>多路召回策略</h3><p>采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合起来供后续排序模型使用。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220722155512.png" alt=""></p>
<p>但是从策略玄策到候选集大小参数的调整都需要人工参与，策略之间的信息也是割裂的，无法综合考虑不同策略对一个物品的影响</p>
<h3 id="基于Embedding的召回方法"><a href="#基于Embedding的召回方法" class="headerlink" title="基于Embedding的召回方法"></a>基于Embedding的召回方法</h3><p>可以将多路召回中使用的“兴趣标签”“热门度”等作为Embedding召回方法中的附加信息融合进最终的Embedding向量中，相当于考虑了多路召回的多种策略。</p>
<p>多路召回中召回策略的相似度、热度等分值不具备可比性，无法据此决定召回策略放回候选集的大小，而Embedding召回可以把Embedding间的相似度作为唯一的判断标准，因此可以随意限定召回的候选集大小。</p>
<h2 id="实时性"><a href="#实时性" class="headerlink" title="实时性"></a>实时性</h2><h3 id="特征的实时性"><a href="#特征的实时性" class="headerlink" title="特征的实时性"></a>特征的实时性</h3><p>实时的收集和更新推荐模型的输入特征，使推荐系统总能使用最新的特征进行预测和推荐。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220722160949.png" alt=""></p>
<h3 id="模型的实时性"><a href="#模型的实时性" class="headerlink" title="模型的实时性"></a>模型的实时性</h3><p>希望更快的抓住全局层面的新数据模型，发现新的趋势和相关性。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220722161213.png" alt=""></p>
<p>局部更新：降低训练效率低的部分的更新频率，提高训练效率高的部分的更新频率。</p>
<p>客户端实时更新：由于客户端算力有限，可以将依赖用户自身数据的部分移植到客户端中，比如用户Embedding。</p>
<h2 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h2><p>充分考虑商业目标和应用场景。</p>
<p>YouTube把视频时长当做优化目标，阿里巴巴提出多目标优化模型ESMM，充分考虑了”曝光到点击“和”点击到转化“两个阶段。</p>
<h2 id="用户行为"><a href="#用户行为" class="headerlink" title="用户行为"></a>用户行为</h2><p>Netflix根据用户的预览图喜好，生成个性化海报。</p>
<p>Smart TV根据用户鼠标的滑动动作判断用户的喜好，解决冷启动问题。</p>
<p>阿里巴巴基于”与候选物品相关的用户行为记录才是有价值的“思路，引入了注意力机制。</p>
<h2 id="冷启动"><a href="#冷启动" class="headerlink" title="冷启动"></a>冷启动</h2><h3 id="基于规则的冷启动过程"><a href="#基于规则的冷启动过程" class="headerlink" title="基于规则的冷启动过程"></a>基于规则的冷启动过程</h3><p>在用户冷启动下可以使用”热门排行榜“”最高评分“等作为默认的推荐列表。也可以参考专家意见，根据用户有限的信息建立一些个性化物品列表。</p>
<p>在物品冷启动场景下，可以根据一些规则找到该物品的相似物品，利用相似物品的推荐逻辑完成物品的冷启动过程。</p>
<h3 id="丰富冷启动过程中可获得的用户和物品特征"><a href="#丰富冷启动过程中可获得的用户和物品特征" class="headerlink" title="丰富冷启动过程中可获得的用户和物品特征"></a>丰富冷启动过程中可获得的用户和物品特征</h3><p>主要包括以下几类：</p>
<p>（1）用户的注册信息</p>
<p>（2）第三方数据管理平台提供的用户信息。</p>
<p>（3）物品的内容特征</p>
<p>（4）引导用户输入的冷启动特征。</p>
<h3 id="利用主动学习、迁移学习和”探索与利用“机制"><a href="#利用主动学习、迁移学习和”探索与利用“机制" class="headerlink" title="利用主动学习、迁移学习和”探索与利用“机制"></a>利用主动学习、迁移学习和”探索与利用“机制</h3><p>主动学习：</p>
<p>不仅利用已有的数据进行建模，而且主动向外界发出询问，获得反馈，从而加速学习过程，生成更全面的模型。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220722164834.png" alt=""></p>
<p>迁移学习：</p>
<p>在某领域知识不足的情况下，迁移其他领域的数据或知识，用于本领域的学习。</p>
<p>探索与利用：</p>
<p>在”探索新数据“和”利用旧数据“之间进行平衡，使系统既能利用旧数据进行推荐，达到推荐系统的商业目标，又能高效的探索冷启动物品是否是”优质“物品，使冷启动物品获得曝光的倾向，快速收集冷启动数据。</p>
<p>通过UCB方法计算每个物品的得分，当物品平均回报高时，或曝光次数低时得分会高，推荐系统倾向于推荐”效果好“或”冷启动“物品。随着冷启动物品有倾向的被推荐，可以快速收集反馈数据，通过冷启动阶段。UCB公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220722165723.png" alt=""></p>
<p>x<sub>j</sub>表示第j个物品的平均回报，n<sub>j</sub>表示第j个物品的曝光次数，n表示所有物品的曝光次数之和。</p>
<h2 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h2><p>”探索与利用“在推荐系统中的应用可以帮助物品冷启动、发掘用户新兴趣、增加结果多样性。”探索与利用“方法分为以下三类。</p>
<p>传统的探索与利用方法：将问题简化成躲避老虎机问题（不知道老虎机信息，按什么顺序选择老虎及可以收益最大化），主要所发有ε贪婪、汤普森采样和UCB。着重解决新物品的探索和利用，不考虑用户、上下文等因素，是非个性化的探索与利用方法。</p>
<p>个性化探索与利用方法：在考虑用户、上下文等因素的基础上进行探索与利用的权衡，如LinUCB算法。</p>
<p>基于模型的探索与利用方法：将深度学医模型和探索与利用的思想进行结合，比如DRN。</p>
<h1 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h1><h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>指训练、服务推荐模型所需数据的处理流程。</p>
<h3 id="批处理大数据架构"><a href="#批处理大数据架构" class="headerlink" title="批处理大数据架构"></a>批处理大数据架构</h3><p>分布式存储+Map Reduce，只能批处理已经落盘的静态数据，无法在数据采集、传输等数据流动的过程中处理数据，框架示意图如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723110523.png" alt=""></p>
<p>只能批量处理分布式文件系统中的数据，因此数据处理的延迟较大，严重影响相关应用的实时性。</p>
<h3 id="流计算大数据架构"><a href="#流计算大数据架构" class="headerlink" title="流计算大数据架构"></a>流计算大数据架构</h3><p>使用”滑动窗口“的概念，在每个”窗口“内部，数据被短暂缓存并消费，在完成一个窗口的数据处理后，流计算平台滑动到下一个时间窗口进行新一轮的数据处理。因此延迟之与滑动窗口的大小有关，基本以分钟级居多，大大缩短了数据延迟。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723112349.png" alt=""></p>
<p>纯流计算又使得平台在数据合法性检查、数据回访、全量数据分析等应用场景下表现较差。</p>
<h3 id="Lambda架构"><a href="#Lambda架构" class="headerlink" title="Lambda架构"></a>Lambda架构</h3><p>分为实时流和离线处理，实时流部分保持了流计算架构，以增量计算为主，保障了数据的实时性，而离线处理则以批处理的方式为主，对数据进行全量运算，保障了数据的最终一致性，为系统提供了更多数据处理的选择。统计数据存入最终数据库之前，将两者进行合并，利用离线层数据对实时流数据进行校验和纠错。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723113143.png" alt=""></p>
<p>但是由于实时流和离线处理部分存在大量逻辑冗余，需要重复地进行编码，浪费了大量计算资源。</p>
<h3 id="Kappa框架"><a href="#Kappa框架" class="headerlink" title="Kappa框架"></a>Kappa框架</h3><p>实时流、离线批处理都以流计算的形式执行。增加”原始数据存储“将未经流处理的数据保存到分布式文件系统，增加”数据重播“将原始数据按时间顺序进行重播，并利用同样的流处理框架进行处理，从而完成离线状态下的数据批处理。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723114317.png" alt=""></p>
<p>当前业界仍以Lambda架构为主，逐渐向Kappa框架靠拢。</p>
<h3 id="大数据处理平台"><a href="#大数据处理平台" class="headerlink" title="大数据处理平台"></a>大数据处理平台</h3><p>对特征和训练样本进行处理，样本和特征数据最终流向两个方向：</p>
<p>（1）以HDFS为代表的离线海量数据存储平台，主要负责存储离线训练用的训练样本。</p>
<p>（2）以Redis为代表的在线实时特征数据库，主要负责为模型的在线服务提供实时特征。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723115459.png" alt=""></p>
<h2 id="离线训练"><a href="#离线训练" class="headerlink" title="离线训练"></a>离线训练</h2><h3 id="Spark-MLlib"><a href="#Spark-MLlib" class="headerlink" title="Spark MLlib"></a>Spark MLlib</h3><p>Spark程序由Cluster Manager（集群管理节点）进行调度组织，由Worker Node（工作节点）进行具体的计算任务执行，最终将结果返回Drive Program（驱动程序）。在物理的Worker Node上，数据还分为不同的Partiton（数据分片），partiton是Spark的基础处理单元。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723121621.png" alt=""></p>
<p>执行具体程序时将程序分解成一个任务DAG（有向无环图），再根据DAG决定程序各步骤执行的方法。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723121906.png" alt=""></p>
<p>处理DAG时需要区分并行处理部分和shuffle、reduce部分。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723122209.png" alt=""></p>
<p>根据shuffle操作划分处理阶段（Stage），Stage内部数据高效并行，边界处进行消耗资源的shuffle操作或最终的reduce操作。</p>
<p>Spark MLlib的并行训练过程是”数据并行“，不涉及过于复杂的梯度更新策略，没有通过”参数并行“实现并行训练。采用全部广播的方式，在每轮迭代前广播全部模型参数，导致Spark面对复杂模型时表现不佳。采用阻断式梯度下降，每轮梯度下降由最慢的节点决定，使得并行训练效率较低。不支持复杂深度学习网络结构和大量可调超参，在深度学习方面能力欠佳。</p>
<h3 id="Parameter-Server"><a href="#Parameter-Server" class="headerlink" title="Parameter Server"></a>Parameter Server</h3><p>用”异步非阻断式“梯度下降代替原来的”同步阻断式“，虽然加快了训练速度，但会带来模型一致性的损失，总体影响不大。</p>
<p>采用服务器节点组内多server的架构，每个server主要负责部分模型，基于一致性哈希提供了参数范围拉取和参数范围推送的能力，如下图</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723125410.png" alt=""></p>
<p>Parameter Server仅是一个管理并行训练梯度的权重平台，不涉及具体模型的实现，往往作为通用的、综合性机器学习平台的组件。</p>
<h3 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h3><p>建立点和边组成的有向图代表某种操作，如下图</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723125825.png" alt=""></p>
<p>对于存在依赖关系的任务节点或者子图串行执行，不存在依赖关系的任务节点或者子图可以并行执行。</p>
<p>TensorFlow的单机训练在一个worker节点上进行，单worker节点内部按照任务关系图的方式在不同GPU+CPU节点间进行并行计算；对于分布式多worker节点，采用TensorFlow的Parameter Server策略，各worker节点以同样的任务关系图的方式进行并行训练，但训练数据不同，产生的梯度以Parameter Server的方式汇总更新。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723130619.png" alt=""></p>
<h2 id="上线部署"><a href="#上线部署" class="headerlink" title="上线部署"></a>上线部署</h2><h3 id="预存推荐结果或Embedding结果"><a href="#预存推荐结果或Embedding结果" class="headerlink" title="预存推荐结果或Embedding结果"></a>预存推荐结果或Embedding结果</h3><p>在离线环境下生成每个用户的推荐结果，然后将结果预存到Redis等线上数据库，在线上环境直接取出预存数据推荐给用户，简单直接无需实现模型线上推断，线上延迟极低，线下训练平台和线上服务平台完全解耦，可以选择任意离线机器学习工具进行模型训练。但是在用户数量、物品数量等规模过大后，容易发生组合爆炸的情况，线上数据库无法支撑，并且无法引入线上场景类特征，推荐系统灵活性受限。</p>
<p>直接预计算并存储用户和物品的Embedding大大减少了存储量，线上也仅需做内积或余弦相似度运算即可得到最终推荐结果，是业界经常采用的模型上线手段。但是同样无法引入线上场景特征，无法进行复杂模型结构的线上推断，表达能力受限。</p>
<h3 id="自研模型线上服务平台"><a href="#自研模型线上服务平台" class="headerlink" title="自研模型线上服务平台"></a>自研模型线上服务平台</h3><p>TensorFlow等通通用平台存在大量功能冗余，自研平台可以根据业务需求进行定制，提高效率。但是时间成本较高，迭代周期过长，往往只在大公司采用。</p>
<h3 id="预训练Embedding-轻量级线上模型"><a href="#预训练Embedding-轻量级线上模型" class="headerlink" title="预训练Embedding+轻量级线上模型"></a>预训练Embedding+轻量级线上模型</h3><p>复杂网络离线训练、生成Embedding存入内存数据库、线上实现逻辑回归或浅层神经网络等轻量级模型拟合优化目标。灵活简单切不过多影响模型效果。</p>
<h3 id="利用PMLL转换并部署模型"><a href="#利用PMLL转换并部署模型" class="headerlink" title="利用PMLL转换并部署模型"></a>利用PMLL转换并部署模型</h3><p>PMML（预测模型标记语言）是一种通用的以XML的形式表示不同模型结构参数的标记语言，经常作为中间媒介连接离线训练平台和线上预测平台。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723143531.png" alt=""></p>
<p>上图使用JPMML作为序列化和解析PMML文件的库，JPMML分为Spark和Java Server两部分，Spark部分完成模型的序列化，生成PMML文件并保存到线上能使用的数据库或文件系统中，Java Server部分完成PMML模型的解析，并生成预估模型，完成与业务逻辑的整合。</p>
<h3 id="TensorFlow-Serving"><a href="#TensorFlow-Serving" class="headerlink" title="TensorFlow Serving"></a>TensorFlow Serving</h3><p>工作流程与PMML类工具一直，不同之处在于TensorFlow定义了自己的模型序列化标准，利用TensorFlow自带的模型序列化函数可将训练好的模型参数和结构保存至某文件路径。在Docker环境中通过拉取镜像的方式即可完成TensorFlow Serving环境的安装和准备。</p>
<h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><h3 id="离线评估方法"><a href="#离线评估方法" class="headerlink" title="离线评估方法"></a>离线评估方法</h3><h3 id="Holdout验证"><a href="#Holdout验证" class="headerlink" title="Holdout验证"></a>Holdout验证</h3><p>将样本随机划分为训练集和验证集，缺点是在验证集上计算出来的评价指标与训练集和验证集的划分有直接关系，结论存在随机性。</p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>k-fold交叉验证：将全部样本划分成k个大小相等的样本子集，依次遍历这k个子集，每次把当前子集作为验证集，其余所有子集作为训练集，最后把k次的评估指标的平均值作为最终的评估指标。k经常取10。</p>
<p>留一验证：将全部样本中的1个样本作为测试集，其他所有样本作为训练集，依次遍历n个样本，进行n次验证，再将评估指标求平均得到最终指标。样本总数多时，时间开销极大。留p验证同理。</p>
<h3 id="自助法"><a href="#自助法" class="headerlink" title="自助法"></a>自助法</h3><p>用于样本规模较小时，对n个样本进行n次有放回随机抽样（一次一个样本），得到大小为n的训练集，将没有被抽出的样本作为验证集进行模型验证。</p>
<h2 id="离线评价指标"><a href="#离线评价指标" class="headerlink" title="离线评价指标"></a>离线评价指标</h2><h3 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h3><p>分类正确的样本占总样本个数的比例</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723163113.png" alt=""></p>
<p>当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。如果推荐问题是点击率预估的分类问题，在选定一个阈值划分正负样本的前提下，可以使用准确率评估模型。实际推荐中更多是得到一个推荐序列，准确率和召回率用的更多。</p>
<h3 id="精确率与召回率"><a href="#精确率与召回率" class="headerlink" title="精确率与召回率"></a>精确率与召回率</h3><p>精确率：分类正确的正样本占分类器判定为正样本的样本个数的比例。</p>
<p>召回率：分类正确的正样本个数占真正正样本的个数比例。</p>
<p>在排序模型中通常采用TopN排序结果的准确率和召回率来衡量排序模型的性能，既TopN的结果就是模型判定的正样本。</p>
<p>为了提高精确率，分类器需要尽量在”更有把握时“才把样本预测为正样本，但往往会因为过于保守而漏掉很多”没有把握“的正样本，导致召回率降低。F1-score可以综合反应精确率和召回率，其定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723164241.png" alt=""></p>
<h3 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h3><p>经常用来衡量回归模型的好坏，定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723164736.png" alt=""></p>
<p>y<sub>i</sub>是第i个样本点的真实值，y<sub>i</sub>hat是第i个样本点的预测值，n是样本点的个数。一般情况下RMSE能很好的反应回归模型预测值与真实值的偏离程度，但如果存在个别偏离程度非常大的离群点，即使数量很少，也会让RMSE指标变差。这是可以使用鲁棒性更强的平均绝对百分比误差（MAPE）进行评估</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723165053.png" alt=""></p>
<p>相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差影响。</p>
<h3 id="对数损失函数"><a href="#对数损失函数" class="headerlink" title="对数损失函数"></a>对数损失函数</h3><p>在一个二分类问题中，LogLoss的定义如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723165336.png" alt=""></p>
<p>LogLoss就是逻辑回归的损失函数，所以是适合观察模型收敛情况的评价指标。</p>
<h2 id="直接评估推荐序列的离线指标"><a href="#直接评估推荐序列的离线指标" class="headerlink" title="直接评估推荐序列的离线指标"></a>直接评估推荐序列的离线指标</h2><h3 id="P-R曲线"><a href="#P-R曲线" class="headerlink" title="P-R曲线"></a>P-R曲线</h3><p>P-R曲线曲线的横坐标是召回率，纵坐标是精确率，整条曲线是通过从高到底移动正样本阈值生成的。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723170831.png" alt=""></p>
<p>上图说明，只用一个点的精确率和召回率不能全面衡量模型性能，只有通过P-R曲线的整体表现，才能对模型进行更全面的评估。在绘制好P-R曲线后，计算曲线下面积（AUC）能够量化P-R曲线的优劣，AUC越大，排序模型的性能越好。</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>ROC曲线的横坐标是FPR（假阳性率），纵坐标是TPR（真阳性率）。计算公式如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723171317.png" alt=""></p>
<p>P是真实的正样本数量，N是真实的负样本数量；TP是P个正样本中被分类器预测为正样本的数量，FP是N个负样本中被分类器预测为正样本的个数。ROC曲线也是通过不断移动模型正样本阈值生成。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723171853.png" alt=""></p>
<h3 id="平均精度均值"><a href="#平均精度均值" class="headerlink" title="平均精度均值"></a>平均精度均值</h3><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723172319.png" alt=""></p>
<p>平均精度AP的计算只取正样本处的precision进行评价，上图的AP=（1/1+2/4+3/5+4/6)/4=0.6917。</p>
<p>mAP就是对所有用户的AP进行平均。</p>
<h2 id="Replay"><a href="#Replay" class="headerlink" title="Replay"></a>Replay</h2><p>动态离线评估方法先根据样本产生时间对测试样本由早到晚进行排序，再用模型根据样本时间进行预测。在模型更新的时间点上，模型需要增量学习更新时间点前的测试样本，更新后继续进行后续的评估。与传统离线评估的对比如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723173535.png" alt=""></p>
<p>如果模型在接收到样本后就更新，这就是经典的离线仿真式更新评估方法-Replay。Replay不仅适用于几乎所有推荐模型的离线评估，而且是强化学习类模型唯一的离线评估方法。</p>
<h2 id="A-B测试"><a href="#A-B测试" class="headerlink" title="A/B测试"></a>A/B测试</h2><p>将用户随机分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型，比较实施组和对照组在各线上评估指标上的差异。相比离线评估，线上A/B测试无法被替代的原因有3点。</p>
<p>（1）离线评估无法完全消除数据有偏现象的影响。</p>
<p>（2）离线评估无法完全还原线上的工程环境。</p>
<p>（3）线上系统的某些商业指标在离线评估中无法计算。</p>
<p>A/B测试的分桶应遵循层与层之间流量”正交“，同层之间的流量”互斥“。层与层之间流量”正交“是指实验中的每组流量穿越该层后都会被再次随机打算，且均匀地分布在下层实现的每个实验组中。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723180038.png" alt=""></p>
<p>同层之间的流量”互斥“是指不同测试之间的流量是不重叠的，一组测试中实验组和对照组的流量是不重叠的。</p>
<p>线上A/B测试的评估指标如下</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723180408.png" alt=""></p>
<h2 id="Interleaving"><a href="#Interleaving" class="headerlink" title="Interleaving"></a>Interleaving</h2><p>解决A/B测试需求和线上A/B测试资料严重不足之间的矛盾，Interleaving作为A//B测试的预选阶段进行候选算法的快速筛选，对缩小的算法集合进行传统A/B测试。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723180901.png" alt=""></p>
<p>灯泡代表候选算法，最优的获胜算法用红色灯泡表示。</p>
<p>为了避免不同分组用户的差异对评估结果的影响，Interleaving不区分A/B分组，而是把不同的被测试对象同时提供给受试者，最后根据受试者喜好得出评估结果。</p>
<p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723181441.png" alt=""></p>
<p>相比A/B测试，Interleaving使用更少的样本（A/B测试样本的1%）就能判断出算法的好坏，即Interleaving的灵敏度更高，同时Interleaving与A/B测试存在非常强的相关性。但是Interleaving的实现较传统A/B测试复杂，Interleaving只是对算法推荐结果偏好程度的相对测量，不能特出一个算法真是的表现。为此，Netflix设计了Interleaving+A/B测试两阶段实验结构，完善整个线上测试的框架。</p>
<h2 id="评估体系"><a href="#评估体系" class="headerlink" title="评估体系"></a>评估体系</h2><p><img src="https://raw.githubusercontent.com/EverestLi/images/main/20220723182413.png" alt=""></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《深度学习推荐系统》王喆，电子工业出版社，2020.3</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/RS/" rel="tag"># RS</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/12/29/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E4%BB%8B/" rel="prev" title="目标检测简介">
      <i class="fa fa-chevron-left"></i> 目标检测简介
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/02/06/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="next" title="李宏毅机器学习笔记">
      李宏毅机器学习笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">经典推荐模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4"><span class="nav-number">1.1.</span> <span class="nav-text">协同过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#UserCF"><span class="nav-number">1.1.1.</span> <span class="nav-text">UserCF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ItemCF"><span class="nav-number">1.1.2.</span> <span class="nav-text">ItemCF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.3.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="nav-number">1.2.</span> <span class="nav-text">矩阵分解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="nav-number">1.2.1.</span> <span class="nav-text">分解方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.2.2.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E9%99%A4%E5%81%8F%E5%B7%AE"><span class="nav-number">1.2.3.</span> <span class="nav-text">消除偏差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">1.2.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">1.3.</span> <span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#POLY2"><span class="nav-number">1.4.</span> <span class="nav-text">POLY2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FM"><span class="nav-number">1.5.</span> <span class="nav-text">FM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FFM"><span class="nav-number">1.6.</span> <span class="nav-text">FFM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GBDT-LR"><span class="nav-number">1.7.</span> <span class="nav-text">GBDT+LR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LS-PLM"><span class="nav-number">1.8.</span> <span class="nav-text">LS-PLM</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">深度学习推荐模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E5%8F%98%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E6%9D%82%E7%A8%8B%E5%BA%A6"><span class="nav-number">2.1.</span> <span class="nav-text">改变神经网络复杂程度</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AutoRec"><span class="nav-number">2.1.1.</span> <span class="nav-text">AutoRec</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Crossing"><span class="nav-number">2.1.2.</span> <span class="nav-text">Deep Crossing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E5%8F%98%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E6%96%B9%E5%BC%8F"><span class="nav-number">2.2.</span> <span class="nav-text">改变特征交叉方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NeuralCF"><span class="nav-number">2.2.1.</span> <span class="nav-text">NeuralCF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PNN"><span class="nav-number">2.2.2.</span> <span class="nav-text">PNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%84%E5%90%88%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.3.</span> <span class="nav-text">组合模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Wide-amp-Deep"><span class="nav-number">2.3.1.</span> <span class="nav-text">Wide&amp;Deep</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-amp-Cross-DCN"><span class="nav-number">2.3.2.</span> <span class="nav-text">Deep&amp;Cross(DCN)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FM%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%BC%94%E5%8C%96%E7%89%88%E6%9C%AC"><span class="nav-number">2.4.</span> <span class="nav-text">FM模型的深度学习演化版本</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#FNN"><span class="nav-number">2.4.1.</span> <span class="nav-text">FNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepFM"><span class="nav-number">2.4.2.</span> <span class="nav-text">DeepFM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NFM"><span class="nav-number">2.4.3.</span> <span class="nav-text">NFM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%B8%8E%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%93%E5%90%88"><span class="nav-number">2.5.</span> <span class="nav-text">注意力机制与推荐模型的结合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AFM"><span class="nav-number">2.5.1.</span> <span class="nav-text">AFM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DIN"><span class="nav-number">2.5.2.</span> <span class="nav-text">DIN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%93%E5%90%88"><span class="nav-number">2.6.</span> <span class="nav-text">序列模型与推荐模型的结合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DIEN"><span class="nav-number">2.6.1.</span> <span class="nav-text">DIEN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BB%93%E5%90%88"><span class="nav-number">2.7.</span> <span class="nav-text">强化学习与推荐模型的结合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DRN"><span class="nav-number">2.7.1.</span> <span class="nav-text">DRN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Embedding%E6%8A%80%E6%9C%AF"><span class="nav-number">3.</span> <span class="nav-text">Embedding技术</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFEnbedding"><span class="nav-number">3.1.</span> <span class="nav-text">什么是Enbedding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word2vec"><span class="nav-number">3.2.</span> <span class="nav-text">Word2vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Item2vec"><span class="nav-number">3.3.</span> <span class="nav-text">Item2vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Graph-Embedding"><span class="nav-number">3.4.</span> <span class="nav-text">Graph Embedding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DeepWalk"><span class="nav-number">3.5.</span> <span class="nav-text">DeepWalk</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Node2vec"><span class="nav-number">3.6.</span> <span class="nav-text">Node2vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EGES"><span class="nav-number">3.7.</span> <span class="nav-text">EGES</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Embedding%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%93%E5%90%88"><span class="nav-number">3.8.</span> <span class="nav-text">Embedding与深度学习推荐系统的结合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">系统工程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="nav-number">4.1.</span> <span class="nav-text">特征工程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%89%B9%E5%BE%81"><span class="nav-number">4.1.1.</span> <span class="nav-text">常用特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95"><span class="nav-number">4.1.2.</span> <span class="nav-text">常用特征的处理方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AC%E5%9B%9E%E7%AD%96%E7%95%A5"><span class="nav-number">4.2.</span> <span class="nav-text">召回策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E%E7%AD%96%E7%95%A5"><span class="nav-number">4.2.1.</span> <span class="nav-text">多路召回策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8EEmbedding%E7%9A%84%E5%8F%AC%E5%9B%9E%E6%96%B9%E6%B3%95"><span class="nav-number">4.2.2.</span> <span class="nav-text">基于Embedding的召回方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E6%97%B6%E6%80%A7"><span class="nav-number">4.3.</span> <span class="nav-text">实时性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E7%9A%84%E5%AE%9E%E6%97%B6%E6%80%A7"><span class="nav-number">4.3.1.</span> <span class="nav-text">特征的实时性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9E%E6%97%B6%E6%80%A7"><span class="nav-number">4.3.2.</span> <span class="nav-text">模型的实时性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-number">4.4.</span> <span class="nav-text">优化目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA"><span class="nav-number">4.5.</span> <span class="nav-text">用户行为</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%B7%E5%90%AF%E5%8A%A8"><span class="nav-number">4.6.</span> <span class="nav-text">冷启动</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%86%B7%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B"><span class="nav-number">4.6.1.</span> <span class="nav-text">基于规则的冷启动过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%B0%E5%AF%8C%E5%86%B7%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%AF%E8%8E%B7%E5%BE%97%E7%9A%84%E7%94%A8%E6%88%B7%E5%92%8C%E7%89%A9%E5%93%81%E7%89%B9%E5%BE%81"><span class="nav-number">4.6.2.</span> <span class="nav-text">丰富冷启动过程中可获得的用户和物品特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%92%8C%E2%80%9D%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8%E2%80%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">4.6.3.</span> <span class="nav-text">利用主动学习、迁移学习和”探索与利用“机制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8"><span class="nav-number">4.7.</span> <span class="nav-text">探索与利用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B7%A5%E7%A8%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">5.</span> <span class="nav-text">工程实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="nav-number">5.1.</span> <span class="nav-text">数据流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%B9%E5%A4%84%E7%90%86%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.1.</span> <span class="nav-text">批处理大数据架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%81%E8%AE%A1%E7%AE%97%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.2.</span> <span class="nav-text">流计算大数据架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lambda%E6%9E%B6%E6%9E%84"><span class="nav-number">5.1.3.</span> <span class="nav-text">Lambda架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kappa%E6%A1%86%E6%9E%B6"><span class="nav-number">5.1.4.</span> <span class="nav-text">Kappa框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0"><span class="nav-number">5.1.5.</span> <span class="nav-text">大数据处理平台</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E8%AE%AD%E7%BB%83"><span class="nav-number">5.2.</span> <span class="nav-text">离线训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib"><span class="nav-number">5.2.1.</span> <span class="nav-text">Spark MLlib</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Parameter-Server"><span class="nav-number">5.2.2.</span> <span class="nav-text">Parameter Server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow"><span class="nav-number">5.2.3.</span> <span class="nav-text">TensorFlow</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8A%E7%BA%BF%E9%83%A8%E7%BD%B2"><span class="nav-number">5.3.</span> <span class="nav-text">上线部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%AD%98%E6%8E%A8%E8%8D%90%E7%BB%93%E6%9E%9C%E6%88%96Embedding%E7%BB%93%E6%9E%9C"><span class="nav-number">5.3.1.</span> <span class="nav-text">预存推荐结果或Embedding结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E7%A0%94%E6%A8%A1%E5%9E%8B%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%B9%B3%E5%8F%B0"><span class="nav-number">5.3.2.</span> <span class="nav-text">自研模型线上服务平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83Embedding-%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BA%BF%E4%B8%8A%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.3.3.</span> <span class="nav-text">预训练Embedding+轻量级线上模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A9%E7%94%A8PMLL%E8%BD%AC%E6%8D%A2%E5%B9%B6%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9E%8B"><span class="nav-number">5.3.4.</span> <span class="nav-text">利用PMLL转换并部署模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow-Serving"><span class="nav-number">5.3.5.</span> <span class="nav-text">TensorFlow Serving</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0"><span class="nav-number">6.</span> <span class="nav-text">评估</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">6.0.1.</span> <span class="nav-text">离线评估方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Holdout%E9%AA%8C%E8%AF%81"><span class="nav-number">6.0.2.</span> <span class="nav-text">Holdout验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">6.0.3.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%8A%A9%E6%B3%95"><span class="nav-number">6.0.4.</span> <span class="nav-text">自助法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="nav-number">6.1.</span> <span class="nav-text">离线评价指标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%86%E7%A1%AE%E7%8E%87"><span class="nav-number">6.1.1.</span> <span class="nav-text">准确率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B2%BE%E7%A1%AE%E7%8E%87%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87"><span class="nav-number">6.1.2.</span> <span class="nav-text">精确率与召回率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE"><span class="nav-number">6.1.3.</span> <span class="nav-text">均方误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">6.1.4.</span> <span class="nav-text">对数损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E8%AF%84%E4%BC%B0%E6%8E%A8%E8%8D%90%E5%BA%8F%E5%88%97%E7%9A%84%E7%A6%BB%E7%BA%BF%E6%8C%87%E6%A0%87"><span class="nav-number">6.2.</span> <span class="nav-text">直接评估推荐序列的离线指标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#P-R%E6%9B%B2%E7%BA%BF"><span class="nav-number">6.2.1.</span> <span class="nav-text">P-R曲线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROC%E6%9B%B2%E7%BA%BF"><span class="nav-number">6.2.2.</span> <span class="nav-text">ROC曲线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B3%E5%9D%87%E7%B2%BE%E5%BA%A6%E5%9D%87%E5%80%BC"><span class="nav-number">6.2.3.</span> <span class="nav-text">平均精度均值</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Replay"><span class="nav-number">6.3.</span> <span class="nav-text">Replay</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#A-B%E6%B5%8B%E8%AF%95"><span class="nav-number">6.4.</span> <span class="nav-text">A&#x2F;B测试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Interleaving"><span class="nav-number">6.5.</span> <span class="nav-text">Interleaving</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB"><span class="nav-number">6.6.</span> <span class="nav-text">评估体系</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="李旭"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">李旭</p>
  <div class="site-description" itemprop="description">学习记录。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/EverestLi" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;EverestLi" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">李旭</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
